{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Notes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research papers of interest\n",
    "These papers are stored at the Arxiv website, they are mostly have not been through peer reviews because they are so new. On the other hand, they are follow up and performed by others researchers and interested users on the internet, if there are problems these will be report almost instantly on the social network.\n",
    "\n",
    "[diffedit](https://arxiv.org/abs/2210.11427)  \n",
    "[Progressive Distillation for Fast Sampling of Diffusion Models](https://arxiv.org/abs/2202.00512)  \n",
    "[On Distillation of Guided Diffusion Models](https://arxiv.org/abs/2210.03142)  \n",
    "[Imagic: Text-Based Real Image Editing with Diffusion Models](https://arxiv.org/abs/2210.09276)  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eistein Summation\n",
    "\n",
    "A technique for convenient and simplify the writing of syntax for many operation in linear algebra\n",
    "\n",
    "- Matrix multiplication\n",
    "- Element-wise matrix operation\n",
    "- Permutation of matrix\n",
    "- Dot product of matrix\n",
    "- Outer product of matrix\n",
    "- Summation of matrix\n",
    "- Batch multiplication of matrix (permute input to match function calls ordering)\n",
    "\n",
    "It's also speedup some of the above operation especially operation that can be combined into single call\n",
    "\n",
    "The eisum is a build-in feature of most Machine learning frameworks, e.g. Pytorch, Tensorflow, Flux..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it work?\n",
    "\n",
    "Here is the matrix multiplication  \n",
    "$$ M_{ij} = \\sum{A_{ik}B_{kj}} = A_{ik}B_{kj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 5), (5, 2), (3, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(3,5)\n",
    "B = np.random.rand(5,2)\n",
    "M = np.empty((3,2))\n",
    "\n",
    "A.shape,B.shape,M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.82759644e-01, 3.32325362e-01, 5.10214353e-01, 8.76891766e-01,\n",
       "         1.72299180e-01],\n",
       "        [5.33438050e-01, 7.25523710e-01, 8.54886776e-01, 3.96140734e-01,\n",
       "         3.56604238e-01],\n",
       "        [5.45349948e-05, 8.97919640e-01, 1.86133084e-01, 8.73382052e-01,\n",
       "         1.11479305e-01]]),\n",
       " array([[0.18449366, 0.69112411],\n",
       "        [0.68456084, 0.92427429],\n",
       "        [0.39745901, 0.59819685],\n",
       "        [0.53124429, 0.82624474],\n",
       "        [0.37620928, 0.55749668]]),\n",
       " array([[1.13621302e-313, 0.00000000e+000],\n",
       "        [6.92770534e-310, 6.92770729e-310],\n",
       "        [6.92770292e-310, 6.92770291e-310]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,B,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=140)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:  \n",
    "Coding as loop of the matrix multiplication above   \n",
    "where the row is i and column is j, and k is the inner dimension of both matrix that must be equal and this index will be summed and disappeared by the operation of matrix rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the matrix is: [[1.09 1.9 ]\n",
      " [1.28 2.08]\n",
      " [1.19 1.73]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        total = 0\n",
    "        for k in range(5):\n",
    "            total += A[i,k] * B[k,j]\n",
    "        M[i,j] = total\n",
    "\n",
    "print(f'the matrix is: {M}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Eisum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the matix is : [[1.09 1.9 ]\n",
      " [1.28 2.08]\n",
      " [1.19 1.73]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the i and j are free index\n",
    "# the k is sum index since it will be summed away after the operation\n",
    "M1 = np.einsum('ik,kj->ij',A,B)\n",
    "\n",
    "print(f'the matix is : {M1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product\n",
    "Vector or matrix multiplicaton $u \\cdot v$  that result of scalar value  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer product \n",
    "vector multiply by vector that result in a matrix $u \\otimes v$  \n",
    "\n",
    "Example 2\n",
    "- Using the free index in the output  \n",
    "- No summation index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the matrix is: \n",
      "[[0.32 0.69 0.7 ]\n",
      " [0.37 0.8  0.8 ]\n",
      " [0.28 0.61 0.61]\n",
      " [0.37 0.79 0.79]\n",
      " [0.17 0.36 0.36]]\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "D = np.random.rand(5)\n",
    "E = np.random.rand(3)\n",
    "out = np.einsum('i,j->ij',D,E)\n",
    "print(f'the matrix is: \\n{out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the matrix is: \n",
      "[[0.32 0.69 0.7 ]\n",
      " [0.37 0.8  0.8 ]\n",
      " [0.28 0.61 0.61]\n",
      " [0.37 0.79 0.79]\n",
      " [0.17 0.36 0.36]]\n"
     ]
    }
   ],
   "source": [
    "# loop version\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        total = 0\n",
    "        total += D[i] * E[j]\n",
    "        out[i,j] = total\n",
    "        \n",
    "print(f'the matrix is: \\n{out}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Eisum Rules\n",
    "\n",
    "The free indices: \n",
    "- The index that specify the output\n",
    "\n",
    "The Summation index  \n",
    "- All other indices that appear in the input argument but not show up in the output\n",
    "\n",
    "The General rules:\n",
    "1. Same index in the a different input argument indicate that these indices will be multiplied and the product are outputed\n",
    "``` python\n",
    "    M = np.einsum('ik,kj->ij',A,B)\n",
    "```\n",
    "2. Omitting index indicate the index will be summed together\n",
    "``` python\n",
    "    X = np.ones(3)\n",
    "    Y = np.einsum('i->',X)\n",
    "```\n",
    "3. The unsummed indices may return in any order\n",
    "``` python\n",
    "    D = np.ones((5,4,3))\n",
    "    E = np.einsum('ijk->kji',D)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operation that benefit from Einsum\n",
    "1. Permutation of Tensors\n",
    "2. Summation\n",
    "3. Column sum\n",
    "4. Row sum\n",
    "5. Matrix-Vector multiplication\n",
    "6. Matrix-Matrix multiplication\n",
    "7. Dot Product the first row with first row of a matrix\n",
    "8. Dot product with matrix (multiplication and add)\n",
    "9. Element-wise multiplication (Hadamard Product) (multiplication no add)\n",
    "10. Outer Product\n",
    "11. Batch matrix multiplicaton e.g. a = 3,2,6 and b = 3,6,3\n",
    "    - want to multiply the matrix of 2x6 with 6x3 matrix\n",
    "    - these matrix must follow the multiplication rule\n",
    "    - the first number  is the batch size they must match, but not count as index \n",
    "    - the torch.bmm function will do the same thing\n",
    "12. Matrix diagonal  \n",
    "    - return the only the diagonal value of the matrix\n",
    "13. Matrix Trace\n",
    "    - summing the value of the diagonal of a matrix  \n",
    "14. Tensor contration  \n",
    "    - shrinking the dimension of tensor  \n",
    "15. Bilinear transformation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.25, 0.74, 0.66],\n",
       "        [0.96, 0.80, 0.44]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140)\n",
    "\n",
    "X = torch.rand((2,3))\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transpose\n",
    "Flipping the matrix or vector by switching the index of a matrix or vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: tensor([[0.25, 0.96],\n",
      "        [0.74, 0.80],\n",
      "        [0.66, 0.44]]) \n",
      "pytorch: tensor([[0.25, 0.96],\n",
      "        [0.74, 0.80],\n",
      "        [0.66, 0.44]])\n",
      " \n",
      "einsum: tensor([[0.25, 0.96],\n",
      "        [0.74, 0.80],\n",
      "        [0.66, 0.44]])\n"
     ]
    }
   ],
   "source": [
    "#| label: mat-transpose\n",
    "#| code-fold: True\n",
    "\n",
    "c_ntp = np.transpose(X)\n",
    "c_tp = torch.transpose(X,0,1)\n",
    "cein = torch.einsum('ij->ji',X)\n",
    "print(f'numpy: {c_ntp} \\npytorch: {c_tp}\\n \\neinsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Matrix summation  \n",
    "Summing all value in the matrix that result in a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: 3.8526394367218018 \n",
      "einsum: 3.8526394367218018\n"
     ]
    }
   ],
   "source": [
    "#| label: matrix-sum\n",
    "\n",
    "#2. Summation\n",
    "cma = torch.sum(X)\n",
    "cein = torch.einsum('ij->',X)\n",
    "\n",
    "print(f'regular: {cma} \\neinsum: {cein}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.25, 0.74, 0.66],\n",
       "        [0.96, 0.80, 0.44]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row sum (Left to right)\n",
    "\n",
    "Add all values from each column together along the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([1.21, 1.54, 1.10]) \n",
      "einsum: tensor([1.65, 2.20])\n"
     ]
    }
   ],
   "source": [
    "#| label: row-summation\n",
    "\n",
    "#4 row summation\n",
    "# sum by columns\n",
    "rows = torch.sum(X,dim=0)\n",
    "cein = torch.einsum('ij->i',X)\n",
    "\n",
    "print(f'regular: {rows} \\neinsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column sum (Top down)\n",
    "\n",
    "Add all value from each row together along the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([1.65, 2.20]) \n",
      "einsum: tensor([1.21, 1.54, 1.10])\n"
     ]
    }
   ],
   "source": [
    "#| label: column-summation\n",
    "\n",
    "#3 Column summation\n",
    "# sum by rows\n",
    "c_col = torch.sum(X,dim=1)\n",
    "cein = torch.einsum('ij->j',X)\n",
    "\n",
    "print(f'regular: {c_col} \\neinsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 matrix-vector multiplication  \n",
    "This a non equal dimension multiplication which in Python use broadcasting to padded (duplicate) the smaller vector to have equal size with the larger matrix before do multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([0.76]) \n",
      "einsum: tensor([0.76])\n"
     ]
    }
   ],
   "source": [
    "#| label: matrix-vector\n",
    "\n",
    "#5 matrix-vector multiplication\n",
    "L = torch.rand((1,3))\n",
    "M = torch.rand((3,))\n",
    "\n",
    "cmm = torch.matmul(L,M)\n",
    "cein = torch.einsum('ij,j->i',L,M)\n",
    "print(f'regular: {cmm} \\neinsum: {cein}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 matrix-matrix multiplication  \n",
    "This standard matrix to matrix multiplication which result in another matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]]) \n",
      "einsum: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "#| label: matrix-matrix\n",
    "\n",
    "#6 matrix-matrix multiplication\n",
    "# torch.einsum('ij,kj->ik',M,M)\n",
    "\n",
    "a = torch.ones((3,2))\n",
    "b = torch.ones((2,3))\n",
    "cmm = torch.matmul(a,b)\n",
    "cein = torch.einsum('ij,jl->il',a,b)\n",
    "print(f'regular: {cmm} \\neinsum: {cein}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.98, 0.72],\n",
       "        [0.64, 0.60],\n",
       "        [1.58, 1.42]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = torch.rand((3,3))\n",
    "M = torch.rand((2,3))\n",
    "torch.einsum('ij,kj->ik',N,M)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product\n",
    "\n",
    "This a matrix multiplication that result in a scalar value. It's usually called multiply add.  \n",
    "since after multiply the row to the column then the sum operation is carry out resulting as a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tensor([0.38, 0.88, 0.10]), c: torch.Size([3])\n",
      "c_dot: 0.3021569550037384\n",
      "regular: 0.3021569550037384 \n",
      "  einsum: 0.3021569550037384\n"
     ]
    }
   ],
   "source": [
    "#| label: dot-product\n",
    "\n",
    "# dot product of a matrix (multiply + add)\n",
    "#torch.einsum('ij,ij->',N,N)\n",
    "\n",
    "# c = torch.tensor([2,3])\n",
    "# d = torch.tensor([2,1])\n",
    "c = torch.rand((3))\n",
    "d = torch.rand((3))\n",
    "\n",
    "c_dot = torch.dot(c,d)\n",
    "cein = torch.einsum('i,i->',c,d)\n",
    "\n",
    "print(f'c: {c}, c: {c.shape}')\n",
    "print(f'c_dot: {c_dot}')\n",
    "print(f'regular: {c_dot} \\n  einsum: {cein}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.89)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product of only the first row of a matrix with first row of a matrix\n",
    "torch.einsum('i,i->',N[0],N[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadamard Product \n",
    "Element wise multiplication (multiply only)  \n",
    "This is a normal matrix multiplication which different from multiply add or dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([[ 1.20,  0.97],\n",
      "        [ 0.14, -0.19],\n",
      "        [-0.17, -0.11]]) \n",
      "  einsum: tensor([[ 1.20,  0.97],\n",
      "        [ 0.14, -0.19],\n",
      "        [-0.17, -0.11]])\n"
     ]
    }
   ],
   "source": [
    "#| label: Hadamard-product\n",
    "\n",
    "# element wise multiplication (multiply only)\n",
    "# torch.einsum('ij,ij->ij',N,N)\n",
    "\n",
    "c = torch.randn((3,2))\n",
    "d = torch.randn((3,2))\n",
    "cmm = c * d\n",
    "cein = torch.einsum('ij,ij->ij',c,d)\n",
    "print(f'regular: {cmm} \\n  einsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer Product\n",
    "\n",
    "Multiply vector of different size to get a matrix as output\n",
    "In eisum must use different letter for index to represent size different\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.91, 0.93, 0.21]), x: torch.Size([3])\n",
      "y: tensor([0.98, 0.62, 0.25, 0.90, 0.21]), y: torch.Size([5])\n",
      "regular: tensor([[0.89, 0.56, 0.23, 0.81, 0.19],\n",
      "        [0.91, 0.57, 0.23, 0.83, 0.19],\n",
      "        [0.20, 0.13, 0.05, 0.18, 0.04]]) \n",
      "  einsum: tensor([[0.89, 0.56, 0.23, 0.81, 0.19],\n",
      "        [0.91, 0.57, 0.23, 0.83, 0.19],\n",
      "        [0.20, 0.13, 0.05, 0.18, 0.04]])\n"
     ]
    }
   ],
   "source": [
    "#| label: outer-product\n",
    "\n",
    "# outer product (inner product)\n",
    "x = torch.rand(3)\n",
    "y = torch.rand(5)\n",
    "print(f'x: {x}, x: {x.shape}')\n",
    "print(f'y: {y}, y: {y.shape}')\n",
    "\n",
    "c_outer = torch.outer(x,y)\n",
    "cein = torch.einsum('i,j->ij',x,y)\n",
    "print(f'regular: {c_outer} \\n  einsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch matrix multiplication  \n",
    "Multiply matrix by the set of n, where n is batch size  \n",
    "\n",
    "want to multiply 3 set of the matrix of 2x6 with 6x3 matrix  \n",
    "the first number is the batch size must match but not count as index so i is ignore  \n",
    "the mxn * nxp must match with n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular: tensor([[[1.55, 1.48, 1.68],\n",
      "         [1.26, 1.02, 1.42]],\n",
      "\n",
      "        [[1.81, 1.20, 1.37],\n",
      "         [1.91, 0.71, 0.93]],\n",
      "\n",
      "        [[0.75, 0.92, 1.20],\n",
      "         [1.32, 1.29, 1.85]]])\n",
      " numpy: tensor([[[1.55, 1.48, 1.68],\n",
      "         [1.26, 1.02, 1.42]],\n",
      "\n",
      "        [[1.81, 1.20, 1.37],\n",
      "         [1.91, 0.71, 0.93]],\n",
      "\n",
      "        [[0.75, 0.92, 1.20],\n",
      "         [1.32, 1.29, 1.85]]]) \n",
      "  einsum: tensor([[[1.55, 1.48, 1.68],\n",
      "         [1.26, 1.02, 1.42]],\n",
      "\n",
      "        [[1.81, 1.20, 1.37],\n",
      "         [1.91, 0.71, 0.93]],\n",
      "\n",
      "        [[0.75, 0.92, 1.20],\n",
      "         [1.32, 1.29, 1.85]]])\n"
     ]
    }
   ],
   "source": [
    "#| label: batch-matrix\n",
    "\n",
    "# batch matrix multiplicaton\n",
    "# want to multiply 3 set of the matrix of 2x6 with 6x3 matrix\n",
    "# the first number is the batch size must match but not count as index so i is ignore\n",
    "# the mxn * nxp must match with n\n",
    "R = torch.rand(3,2,6)\n",
    "S = torch.rand(3,6,3)\n",
    "cmn = np.matmul(R,S)\n",
    "cmm = torch.matmul(R,S)\n",
    "\n",
    "cein = torch.einsum('ijk,ikl->ijl',R,S)\n",
    "\n",
    "print(f'regular: {cmm}\\n numpy: {cmn} \\n  einsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagonal Matrix\n",
    "return the vector of value along the diagonal of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: tensor([[0.33, 0.11, 0.63],\n",
      "        [0.60, 0.82, 0.28],\n",
      "        [0.08, 0.99, 0.18]]) \n",
      "T shape: torch.Size([3, 3])\n",
      "regular: tensor([0.33, 0.82, 0.18]) \n",
      "  einsum: tensor([0.33, 0.82, 0.18])\n"
     ]
    }
   ],
   "source": [
    "#| label: diag-mat\n",
    "\n",
    "# Diagonal matrix return only the diagonal value of a matrix\n",
    "\n",
    "T = torch.rand(3,3)\n",
    "\n",
    "cein = torch.einsum('ii->i',T)\n",
    "print(f'T: {T} \\nT shape: {T.shape}')\n",
    "c_diag = torch.diag(T)\n",
    "\n",
    "print(f'regular: {c_diag} \\n  einsum: {cein}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.einsum('ii->i',T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace\n",
    "\n",
    "Take the sum of all values along the diagonal axix of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: tensor([[0.33, 0.11, 0.63],\n",
      "        [0.60, 0.82, 0.28],\n",
      "        [0.08, 0.99, 0.18]])\n",
      "regular: 1.3291736841201782 \n",
      "  einsum: 1.3291736841201782\n"
     ]
    }
   ],
   "source": [
    "#| label: trace\n",
    "\n",
    "# matrix trace\n",
    "\n",
    "c_trace = torch.trace(T)\n",
    "cein = torch.einsum('ii->',T)\n",
    "print(f'T: {T}')\n",
    "print(f'regular: {c_trace} \\n  einsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Contraction  \n",
    "Shrinking the dimension of the tensor  \n",
    "must provide the dimension to be ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: torch.Size([3, 4, 2]) value2: torch.Size([4, 3, 6])\n",
      "regular: tensor([[3.72, 2.19, 3.15, 3.26, 2.88, 1.90],\n",
      "        [5.16, 3.22, 4.84, 4.64, 4.52, 3.33]]) \n",
      "  einsum: tensor([[3.72, 2.19, 3.15, 3.26, 2.88, 1.90],\n",
      "        [5.16, 3.22, 4.84, 4.64, 4.52, 3.33]])\n"
     ]
    }
   ],
   "source": [
    "#| label: contraction\n",
    "\n",
    "o = torch.rand((3,4,2))\n",
    "p = torch.rand((4,3,6))\n",
    "print(f'value: {o.shape} value2: {p.shape}')\n",
    "\n",
    "c_tdot = torch.tensordot(o,p,dims=([1,0],[0,1]))\n",
    "cein = torch.einsum('ijk,jil->kl',o,p)\n",
    "print(f'regular: {c_tdot} \\n  einsum: {cein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilinear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.12, 3.11, 2.71, 3.34, 2.55],\n",
       "        [3.39, 2.72, 2.68, 3.09, 2.96]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "b = torch.rand(5,3,7)\n",
    "c = torch.rand(2,7)\n",
    "\n",
    "torch.einsum('ik,jkl,il->ij',[a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
